{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sumy.parsers.plaintext import PlaintextParser\n",
    "from sumy.nlp.tokenizers import Tokenizer\n",
    "from sumy.summarizers.text_rank import TextRankSummarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extractive summarizaition of text using TextRank algorithm\n",
    "def extractive_summarisation(text: str , num_sentences: int = 3) -> str:\n",
    "    \"\"\"Generates an extractive summary of the text using the TextRank algorithm\n",
    "\n",
    "    Args:\n",
    "        text (str): The input text to summarize\n",
    "        num_sentences (int, optional): The number of sentences in the summary. Defaults to 3.\n",
    "\n",
    "    Returns:\n",
    "        str: the extractive summary containing the most \n",
    "    \"\"\"\n",
    "    # converts the text into a sumy understandable format\n",
    "    parser = PlaintextParser.from_string(text, Tokenizer(\"english\")) \n",
    "    \n",
    "    # Instance of TextRank Summarizer (graph-based algorithm )\n",
    "    summarizer = TextRankSummarizer()\n",
    "\n",
    "    # Generating summary containing the top-ranked sentences \n",
    "    summary = summarizer(parser.document, num_sentences) \n",
    "\n",
    "    # converting the list of sentences into a single text summary\n",
    "    summary = \" \".join(str(sentence) for sentence in summary )\n",
    "    \n",
    "    #print(summary)\n",
    "    return summary \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentient toaster pondered the existential dread of burnt toast, its neural network humming with anxieties about butter distribution and the fleeting nature of crispy perfection. Meanwhile, the self-driving car, lost in a philosophical debate with a traffic cone, nearly collided with a bewildered squirrel.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    text = \"\"\"The sentient toaster pondered the existential dread of burnt toast, \n",
    "    its neural network humming with anxieties about butter distribution and the fleeting nature of crispy perfection.\n",
    "    Meanwhile, the self-driving car, \n",
    "    lost in a philosophical debate with a traffic cone, nearly collided with a bewildered squirrel.\n",
    "    \"\"\"\n",
    "    extractive_summarisation(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
